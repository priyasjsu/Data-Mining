# -*- coding: utf-8 -*-
"""PredictRestaurant.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qwf4-FMGv9pMDLn2mPLgz-dlyAIzgFtY
"""
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import LatentDirichletAllocation
import warnings
# Ignore all warnings
warnings.filterwarnings("ignore")
#!pip install scikit-surprise
from surprise import Reader, Dataset
from sklearn.model_selection import train_test_split
from surprise import SVD
from surprise import Dataset
from surprise.model_selection import train_test_split

import numpy as np
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.tokenize import sent_tokenize, word_tokenize 
from nltk.corpus import stopwords
import re
import ssl
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
import pickle
import random
import nltk
import os

#nltk.download('vader_lexicon')

#nltk.download('stopwords')

#nltk.download('punkt')


class prediction:
    def __init__(self):
        # Load the data and trained_models from files
        my_path = os.path.abspath(os.path.dirname(__file__))
        file_path = os.path.join(my_path, "../data/train_svd_data.pkl")

        with open(file_path, "rb") as f:
            self.data = pickle.load(f)

        file_path1 = os.path.join(my_path, "../data/trained_model.pkl")

        with open(file_path1, "rb") as f:
            self.trained_models = pickle.load(f)

    def make_recommendations(self, user_id):
        # Filter the review data for the given user ID
        user_data = self.data

        # Get recommendations using the trained model from trained_models
        trained_model = self.trained_models
        user_predictions = []
        for _, row in user_data.iterrows():
            prediction = trained_model.predict(user_id, row['restaurant_id'])
            user_predictions.append((prediction.est, prediction.iid))

        recommendations_cf = pd.DataFrame(user_predictions, columns=['rating', 'restaurant_id'])
        recommendations_cf = recommendations_cf.merge(self.data, on='restaurant_id')

        return recommendations_cf

    def get_random_user_id(self,data):
        random_user_id = random.choice(data['user_id'].unique())
        return random_user_id

    def predict(self):

        random_user_id= self.get_random_user_id(self.data)
        recommendations_cf= self.make_recommendations(random_user_id)

        recommendations_cf= recommendations_cf.sort_values('rating_x',ascending=False)
        
        print(f'Top Recommended Restaurants for User {random_user_id}')

        print("---------------------")
        
        count= 1


        for i in recommendations_cf.name.unique():

            print(f'{count}. ', i)

            print("\n")
            count += 1
            if count == 6:
                break


# Create an instance of the PREDICTModel class
model = prediction()

# Generate a random user ID
#random_user_id = get_random_user_id(model.data)

# Make recommendations for the random user ID
recommendations = model.predict()

# Print or process the recommendations as needed
