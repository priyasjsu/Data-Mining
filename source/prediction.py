# -*- coding: utf-8 -*-
"""PredictRestaurant.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qwf4-FMGv9pMDLn2mPLgz-dlyAIzgFtY
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import LatentDirichletAllocation

from surprise import Reader, Dataset
from sklearn.model_selection import train_test_split
from surprise import SVD
from surprise import Dataset
from surprise.model_selection import train_test_split

import pandas as pd
import numpy as np
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import re
import ssl
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel

import requests
import pickle
import random


class prediction:
    def __init__(self, fileid):
        """ Function to load trained svd model and data"""

        # Define the URL to download the data
        url = f'https://drive.google.com/uc?id={fileid[0]}'

        # Send a GET request to download the file
        response = requests.get(url)

        # Load the downloaded content as a pickle object
        self.data = pickle.loads(response.content)

        # Define the URL to download the svd model
        url = f'https://drive.google.com/uc?id={fileid[1]}'

        # Send a GET request to download the file
        response = requests.get(url)

        self.trained_models = pickle.loads(response.content)

    def make_recommendations(self, user_id):
        """ Function to generate random user id and recommend chinese restaurant in philadelphia"""
        # Filter the review data for the given user ID
        user_data = self.data

        # Get recommendations using the trained model from trained_models
        trained_model = self.trained_models
        user_predictions = []
        for _, row in user_data.iterrows():
            prediction = trained_model.predict(user_id, row['restaurant_id'])
            user_predictions.append((prediction.est, prediction.iid))

        recommendations_cf = pd.DataFrame(user_predictions, columns=['rating', 'restaurant_id'])
        recommendations_cf = recommendations_cf.merge(self.data, on='restaurant_id')

        return recommendations_cf

    def get_random_user_id(self, data):
        """ random user id generation. in real scenario we can mention specific username or id"""
        random_user_id = random.choice(data['user_id'].unique())
        return random_user_id

    def predict(self):
        """ predicting the top 10 restaurant based on rating"""

        random_user_id = self.get_random_user_id(self.data)
        recommendations_cf = self.make_recommendations(random_user_id)

        recommendations_cf = recommendations_cf.sort_values('rating_x', ascending=False)

        print(f'Top Recommended Restaurants for User {random_user_id}')

        print("---------------------")

        count = 1
        name = ""
        for i, j in recommendations_cf.iterrows():

            if name != j['name']:
                print(f'{count}. ', j['name'], end=' ')
                print('Location: ', j['city'], end=' ')
                print('Rating: ', j['rating_x'])
                print("\n")
                count += 1
                if count == 6:
                    break

            name = j['name']


# Create an instance of the PREDICTModel class
model = prediction(['14hR-g6u3zFFhBW39-W9fRBKkWUJC2Xt9', '1qsm1aX4syg43XXDiDMAPXWw4E6mxQzh3'])

# Make recommendations for the random user ID
recommendations = model.predict()

# Print or process the recommendations as needed
