"""PredictRestaurant.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qwf4-FMGv9pMDLn2mPLgz-dlyAIzgFtY
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import LatentDirichletAllocation

import warnings

# Ignore all warnings
warnings.filterwarnings("ignore")

# !pip install scikit-surprise

from surprise import Reader, Dataset
from sklearn.model_selection import train_test_split
from surprise import SVD
from surprise import Dataset
from surprise.model_selection import train_test_split

import pandas as pd
import numpy as np
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import re
import ssl
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk

nltk.download('vader_lexicon')

nltk.download('stopwords')

nltk.download('punkt')

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel

import pickle
import random


class prediction:
    def __init__(self):
        # Load the data and trained_models from files
        with open("/Users/iqrabismi/Desktop/DMProject/train_svd_data.pkl", "rb") as f:
            self.data = pickle.load(f)
        with open("/Users/iqrabismi/Desktop/DMProject/trained_model.pkl", "rb") as f:
            self.trained_models = pickle.load(f)

    def make_recommendations(self, user_id):
        # Filter the review data for the given user ID
        user_data = self.data

        # Get recommendations using the trained model from trained_models
        trained_model = self.trained_models
        user_predictions = []
        for _, row in user_data.iterrows():
            prediction = trained_model.predict(user_id, row['restaurant_id'])
            user_predictions.append((prediction.est, prediction.iid))

        recommendations_cf = pd.DataFrame(user_predictions, columns=['rating', 'restaurant_id'])
        recommendations_cf = recommendations_cf.merge(self.data, on='restaurant_id')

        return recommendations_cf

    def get_random_user_id(self, data):
        random_user_id = random.choice(data['user_id'].unique())
        return random_user_id

    def predict(self):

        random_user_id = self.get_random_user_id(self.data)
        recommendations_cf = self.make_recommendations(random_user_id)

        recommendations_cf = recommendations_cf.sort_values('rating_x', ascending=False)

        print(f'Top Recommended Restaurants for User {random_user_id}')

        print("---------------------")
        count = 1
        for i in recommendations_cf.name.unique():
            print(f'{count}. ', i)
            count += 1
            if count == 11:
                break


# Create an instance of the PREDICTModel class
model = prediction()

# Generate a random user ID
# random_user_id = get_random_user_id(model.data)

# Make recommendations for the random user ID
recommendations = model.predict()

# Print or process the recommendations as needed